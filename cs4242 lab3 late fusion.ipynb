{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4242 Lab 3: Viral Item Prediction in Social Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single feature regressions\n",
    "### 1. Image color histogram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "The input data dimension is: (10000, 3)\n",
      "Start training and predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round of nMSE is: 0.997819\n",
      "This round of nMSE is: 0.997361\n",
      "This round of nMSE is: 0.995921\n",
      "This round of nMSE is: 0.999888\n",
      "This round of nMSE is: 0.999960\n",
      "This round of nMSE is: 0.998815\n",
      "This round of nMSE is: 0.997827\n",
      "This round of nMSE is: 0.999911\n",
      "This round of nMSE is: 0.997693\n",
      "This round of nMSE is: 0.999816\n",
      "Average nMSE is 0.998501.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './data/' \n",
    "\n",
    "# load data\n",
    "print(\"Loading data...\")\n",
    "hist_feature = np.load(data_dir + 'histogram_feature.npz')['arr_0']\n",
    "\n",
    "# feature dimension reduction: it's up to you to decide the size of reduced dimensions; the main purpose is to reduce the computation complexity\n",
    "pca = PCA(n_components=3)\n",
    "hist_feature = pca.fit_transform(hist_feature)\n",
    "\n",
    "# contatenate all the features(after dimension reduction)\n",
    "concat_feature = np.concatenate([hist_feature], axis=1)\n",
    "concat_feature = scale(concat_feature)\n",
    "print(\"The input data dimension is: (%d, %d)\" %(concat_feature.shape))\n",
    "\n",
    "# load ground-truth\n",
    "ground_truth = []\n",
    "for line in open(os.path.join(data_dir, 'ground_truth.txt')):\n",
    "    #you can use more than one popularity index as ground-truth and average the results; for each video we have four indexes: number of loops(view), likes, reposts, and comments; the first one(loops) is compulsory.\n",
    "    ground_truth.append(float(line.strip().split('::::')[0])) \n",
    "ground_truth = np.array(ground_truth, dtype=np.float32)\n",
    "\n",
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "pred_hist = np.empty(shape=[0,1])\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR(http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = SVR(C=5000000, gamma=1e-05, epsilon=0.01, kernel='rbf')\n",
    "    # train\n",
    "    model.fit(concat_feature[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(concat_feature[test])\n",
    "    pred_hist = np.concatenate((pred_hist,predicts.reshape(1000,1)),axis=0)\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. imgNet_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data dimension is: (10000, 5)\n",
      "Start training and predict...\n",
      "This round of nMSE is: 0.997906\n",
      "This round of nMSE is: 0.997687\n",
      "This round of nMSE is: 0.995760\n",
      "This round of nMSE is: 0.999906\n",
      "This round of nMSE is: 0.999957\n",
      "This round of nMSE is: 0.998760\n",
      "This round of nMSE is: 0.997861\n",
      "This round of nMSE is: 0.999908\n",
      "This round of nMSE is: 0.997613\n",
      "This round of nMSE is: 0.999818\n",
      "Average nMSE is 0.998518.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './data/' \n",
    "\n",
    "# load data\n",
    "print(\"Loading data...\")\n",
    "imgNet_feature = np.load(data_dir + 'imageNet_feature.npz')['arr_0']\n",
    "\n",
    "### feature dimension reduction: I tried to reduce dimensions without increasing nMSE ###\n",
    "pca = PCA(n_components=5)\n",
    "imgNet_feature = pca.fit_transform(imgNet_feature)\n",
    "\n",
    "# contatenate all the features(after dimension reduction)\n",
    "concat_feature = np.concatenate([imgNet_feature], axis=1) \n",
    "concat_feature = scale(concat_feature)\n",
    "print(\"The input data dimension is: (%d, %d)\" %(concat_feature.shape))\n",
    "\n",
    "# load ground-truth\n",
    "ground_truth = []\n",
    "for line in open(os.path.join(data_dir, 'ground_truth.txt')):\n",
    "    #you can use more than one popularity index as ground-truth and average the results; for each video we have four indexes: number of loops(view), likes, reposts, and comments; the first one(loops) is compulsory.\n",
    "    ground_truth.append(float(line.strip().split('::::')[0])) \n",
    "ground_truth = np.array(ground_truth, dtype=np.float32)\n",
    "\n",
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "pred_imageNet = np.empty(shape=[0,1])\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = SVR(C=5000000, gamma=1e-05, epsilon=0.01, kernel='rbf')\n",
    "    # train\n",
    "    model.fit(concat_feature[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(concat_feature[test])\n",
    "    pred_imageNet = np.concatenate((pred_imageNet,predicts.reshape(1000,1)))\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. vSenti_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data dimension is: (10000, 10)\n",
      "Start training and predict...\n",
      "This round of nMSE is: 0.997626\n",
      "This round of nMSE is: 0.996819\n",
      "This round of nMSE is: 0.994465\n",
      "This round of nMSE is: 0.999845\n",
      "This round of nMSE is: 0.999956\n",
      "This round of nMSE is: 0.998602\n",
      "This round of nMSE is: 0.997636\n",
      "This round of nMSE is: 0.999909\n",
      "This round of nMSE is: 0.997714\n",
      "This round of nMSE is: 0.999687\n",
      "Average nMSE is 0.998226.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './data/' \n",
    "\n",
    "# load data\n",
    "print(\"Loading data...\")\n",
    "vSenti_feature = np.load(data_dir + 'visual_senti_feature.npz')['arr_0']\n",
    "\n",
    "### feature dimension reduction: I tried to reduce dimensions without increasing nMSE ###\n",
    "pca = PCA(n_components=10)\n",
    "vSenti_feature = pca.fit_transform(vSenti_feature)\n",
    "\n",
    "# contatenate all the features(after dimension reduction)\n",
    "concat_feature = np.concatenate([vSenti_feature], axis=1) \n",
    "concat_feature = scale(concat_feature)\n",
    "print(\"The input data dimension is: (%d, %d)\" %(concat_feature.shape))\n",
    "\n",
    "# load ground-truth\n",
    "ground_truth = []\n",
    "for line in open(os.path.join(data_dir, 'ground_truth.txt')):\n",
    "    #you can use more than one popularity index as ground-truth and average the results; for each video we have four indexes: number of loops(view), likes, reposts, and comments; the first one(loops) is compulsory.\n",
    "    ground_truth.append(float(line.strip().split('::::')[0])) \n",
    "ground_truth = np.array(ground_truth, dtype=np.float32)\n",
    "\n",
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "pred_vSenti = np.empty(shape=[0,1])\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = SVR(C=5000000, gamma=1e-05, epsilon=0.01, kernel='rbf')\n",
    "    # train\n",
    "    model.fit(concat_feature[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(concat_feature[test])\n",
    "    pred_vSenti = np.concatenate((pred_vSenti,predicts.reshape(1000,1)))\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. text_sentence2vec_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "The input data dimension is: (10000, 3)\n",
      "Start training and predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round of nMSE is: 0.997000\n",
      "This round of nMSE is: 0.997235\n",
      "This round of nMSE is: 0.994146\n",
      "This round of nMSE is: 0.999898\n",
      "This round of nMSE is: 0.999970\n",
      "This round of nMSE is: 0.998909\n",
      "This round of nMSE is: 0.997712\n",
      "This round of nMSE is: 0.999912\n",
      "This round of nMSE is: 0.997701\n",
      "This round of nMSE is: 0.999820\n",
      "Average nMSE is 0.998230.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './data/' \n",
    "\n",
    "# load data\n",
    "print(\"Loading data...\")\n",
    "sen2vec_feature = np.load(data_dir + 'text_sentence2vec_feature.npz')['arr_0']\n",
    "\n",
    "### feature dimension reduction: I tried to reduce dimensions without increasing nMSE ###\n",
    "pca = PCA(n_components=3)\n",
    "sen2vec_feature = pca.fit_transform(sen2vec_feature)\n",
    "\n",
    "# contatenate all the features(after dimension reduction)\n",
    "concat_feature = np.concatenate([sen2vec_feature], axis=1) \n",
    "concat_feature = scale(concat_feature)\n",
    "print(\"The input data dimension is: (%d, %d)\" %(concat_feature.shape))\n",
    "\n",
    "# load ground-truth\n",
    "ground_truth = []\n",
    "for line in open(os.path.join(data_dir, 'ground_truth.txt')):\n",
    "    #you can use more than one popularity index as ground-truth and average the results; for each video we have four indexes: number of loops(view), likes, reposts, and comments; the first one(loops) is compulsory.\n",
    "    ground_truth.append(float(line.strip().split('::::')[0])) \n",
    "ground_truth = np.array(ground_truth, dtype=np.float32)\n",
    "\n",
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "pred_s2v = np.empty(shape=[0,1])\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = SVR(C=5000000, gamma=1e-05, epsilon=0.01, kernel='rbf')\n",
    "    # train\n",
    "    model.fit(concat_feature[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(concat_feature[test])\n",
    "    pred_s2v = np.concatenate((pred_s2v,predicts.reshape(1000,1)))\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. social features (with user description and video description sentiment scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "The input data dimension is: (10000, 8)\n",
      "Start training and predict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\h\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round of nMSE is: 0.801686\n",
      "This round of nMSE is: 0.937534\n",
      "This round of nMSE is: 0.696242\n",
      "This round of nMSE is: 0.951435\n",
      "This round of nMSE is: 0.997843\n",
      "This round of nMSE is: 0.986784\n",
      "This round of nMSE is: 0.922323\n",
      "This round of nMSE is: 0.998810\n",
      "This round of nMSE is: 0.789873\n",
      "This round of nMSE is: 0.972943\n",
      "Average nMSE is 0.905547.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_social_features(video_id, video_user, user_details, user_des_score, video_des_score):\n",
    "    vid = [] #video id list\n",
    "    for line in open(video_id):\n",
    "        vid.append(line.strip())\n",
    "   \n",
    "    vid_uid_dict = {} #vid-uid mapping\n",
    "    for line in open(video_user):\n",
    "        data = line.strip().split('::::')\n",
    "        vid_uid_dict[data[0]] = data[1]\n",
    "    \n",
    "    social_features = {} #uid-social_feature mapping\n",
    "    ### here I add 5 social features: following count of the user, like count of the user, ###\n",
    "    ### post count of the user, twitter verified flag and user description sentiment score ###\n",
    "    ### I also add video description sentiment score here. ###\n",
    "    with open(user_details,encoding='utf-8') as f1, open(user_des_score,encoding='utf-8') as f2, open(video_des_score,encoding='utf-8') as f3:\n",
    "        data = [line.strip().split(\"::::\") for line in f1]\n",
    "        scores1 = [line.strip() for line in f2]\n",
    "        scores2 = [line.strip() for line in f3]\n",
    "        for i,d in enumerate(data):\n",
    "            s1 = float(scores1[i])\n",
    "            s2 = float(scores2[i])\n",
    "            l = [float(n) for n in d[1:7]]\n",
    "            l.append(s1)\n",
    "            l.append(s2)\n",
    "            social_features[d[0]] = l\n",
    "    \n",
    "    res = [] #social_feature vector for each video\n",
    "    for v in vid:\n",
    "        try:\n",
    "            res.append(social_features[vid_uid_dict[v]])\n",
    "        except:\n",
    "            #note: there are some users don't have social features, just assgin zero-vector to them\n",
    "            res.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) \n",
    "\n",
    "    return np.array(res, dtype=np.float32) \n",
    "\n",
    "\n",
    "data_dir = './data/' \n",
    "\n",
    "# load data\n",
    "print(\"Loading data...\")\n",
    "social_feature = load_social_features(data_dir + 'video_id.txt', data_dir + 'video_user.txt', data_dir + 'user_details.txt',data_dir + 'user_des_scores.txt',data_dir + 'video_des_scores.txt')\n",
    "\n",
    "# contatenate all the features(after dimension reduction)\n",
    "concat_feature = np.concatenate([social_feature], axis=1) \n",
    "concat_feature = scale(concat_feature)\n",
    "print(\"The input data dimension is: (%d, %d)\" %(concat_feature.shape))\n",
    "\n",
    "# load ground-truth\n",
    "ground_truth = []\n",
    "for line in open(os.path.join(data_dir, 'ground_truth.txt')):\n",
    "    #you can use more than one popularity index as ground-truth and average the results; for each video we have four indexes: number of loops(view), likes, reposts, and comments; the first one(loops) is compulsory.\n",
    "    ground_truth.append(float(line.strip().split('::::')[0])) \n",
    "ground_truth = np.array(ground_truth, dtype=np.float32)\n",
    "\n",
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "pred_social = np.empty(shape=[0,1])\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = SVR(C=5000000, gamma=1e-05, epsilon=0.01, kernel='rbf')\n",
    "    # train\n",
    "    model.fit(concat_feature[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(concat_feature[test])\n",
    "    pred_social = np.concatenate((pred_social,predicts.reshape(1000,1)))\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n"
     ]
    }
   ],
   "source": [
    "pred_final = np.concatenate((pred_hist,pred_imageNet,pred_vSenti, pred_s2v, pred_social),axis=1)\n",
    "print(pred_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late fusion\n",
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average nMSE is 1.802463.\n",
      "Average nMSE is 1.613501.\n",
      "Average nMSE is 1.471380.\n",
      "Average nMSE is 1.362437.\n",
      "Average nMSE is 1.277583.\n",
      "Average nMSE is 1.210591.\n",
      "Average nMSE is 1.157088.\n",
      "Average nMSE is 1.113933.\n",
      "Average nMSE is 1.078828.\n",
      "Average nMSE is 1.050061.\n",
      "Average nMSE is 1.026341.\n",
      "Average nMSE is 1.006676.\n",
      "Average nMSE is 0.990301.\n",
      "Average nMSE is 0.976614.\n",
      "Average nMSE is 0.965141.\n",
      "Average nMSE is 0.955500.\n",
      "Average nMSE is 0.947388.\n",
      "Average nMSE is 0.940555.\n",
      "Average nMSE is 0.934800.\n",
      "Average nMSE is 0.929956.\n",
      "Average nMSE is 0.925886.\n",
      "Average nMSE is 0.922476.\n",
      "Average nMSE is 0.919629.\n",
      "Average nMSE is 0.917265.\n",
      "Average nMSE is 0.915317.\n",
      "Average nMSE is 0.913728.\n",
      "Average nMSE is 0.912448.\n",
      "Average nMSE is 0.911436.\n",
      "Average nMSE is 0.910656.\n",
      "Average nMSE is 0.910079.\n",
      "Average nMSE is 0.909676.\n",
      "Average nMSE is 0.909427.\n",
      "Average nMSE is 0.909310.\n",
      "Average nMSE is 0.909309.\n",
      "Average nMSE is 0.909409.\n",
      "Average nMSE is 0.909597.\n",
      "Average nMSE is 0.909861.\n",
      "Average nMSE is 0.910192.\n",
      "Average nMSE is 0.910581.\n",
      "Average nMSE is 0.911020.\n",
      "Average nMSE is 0.911503.\n",
      "Average nMSE is 0.912023.\n",
      "Average nMSE is 0.912575.\n",
      "Average nMSE is 0.913155.\n",
      "Average nMSE is 0.913759.\n",
      "Average nMSE is 0.914383.\n",
      "Average nMSE is 0.915023.\n",
      "Average nMSE is 0.915677.\n",
      "Average nMSE is 0.916343.\n",
      "Average nMSE is 0.917019.\n",
      "Average nMSE is 0.917701.\n",
      "Average nMSE is 0.918389.\n",
      "Average nMSE is 0.919081.\n",
      "Average nMSE is 0.919775.\n",
      "Average nMSE is 0.920471.\n",
      "Average nMSE is 0.921167.\n",
      "Average nMSE is 0.921863.\n",
      "Average nMSE is 0.922557.\n",
      "Average nMSE is 0.923249.\n",
      "Average nMSE is 0.923938.\n",
      "Average nMSE is 0.924623.\n",
      "Average nMSE is 0.925305.\n",
      "Average nMSE is 0.925982.\n",
      "Average nMSE is 0.926654.\n",
      "Average nMSE is 0.927321.\n",
      "Average nMSE is 0.927982.\n",
      "Average nMSE is 0.928638.\n",
      "Average nMSE is 0.929288.\n",
      "Average nMSE is 0.929932.\n",
      "Average nMSE is 0.930570.\n",
      "Average nMSE is 0.931201.\n",
      "Average nMSE is 0.931826.\n",
      "Average nMSE is 0.932444.\n",
      "Average nMSE is 0.933055.\n",
      "Average nMSE is 0.933660.\n",
      "Average nMSE is 0.934258.\n",
      "Average nMSE is 0.934850.\n",
      "Average nMSE is 0.935435.\n",
      "Average nMSE is 0.936012.\n",
      "Average nMSE is 0.936584.\n",
      "Average nMSE is 0.937148.\n",
      "Average nMSE is 0.937706.\n",
      "Average nMSE is 0.938257.\n",
      "Average nMSE is 0.938802.\n",
      "Average nMSE is 0.939340.\n",
      "Average nMSE is 0.939872.\n",
      "Average nMSE is 0.940397.\n",
      "Average nMSE is 0.940916.\n",
      "Average nMSE is 0.941428.\n",
      "Average nMSE is 0.941935.\n",
      "Average nMSE is 0.942435.\n",
      "Average nMSE is 0.942929.\n",
      "Average nMSE is 0.943417.\n",
      "Average nMSE is 0.943899.\n",
      "Average nMSE is 0.944375.\n",
      "Average nMSE is 0.944845.\n",
      "Average nMSE is 0.945309.\n",
      "Average nMSE is 0.945768.\n",
      "Average nMSE is 0.946222.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "for alpha in range(1,100):\n",
    "    kf = KFold(n_splits=10)\n",
    "    nMSEs = []\n",
    "    for train, test in kf.split(pred_final):\n",
    "        model = linear_model.Ridge(alpha=alpha/10, normalize=True)\n",
    "        # train\n",
    "        model.fit(pred_final[train], ground_truth[train])\n",
    "        # predict\n",
    "        predicts = model.predict(pred_final[test])\n",
    "        # nMSE(normalized Mean Squared Error) metric calculation\n",
    "        nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "        nMSEs.append(nMSE)\n",
    "\n",
    "    print('Average nMSE is %f.' %(np.mean(nMSEs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round of nMSE is: 0.793356\n",
      "This round of nMSE is: 0.935642\n",
      "This round of nMSE is: 0.690246\n",
      "This round of nMSE is: 0.950290\n",
      "This round of nMSE is: 0.997754\n",
      "This round of nMSE is: 0.985787\n",
      "This round of nMSE is: 0.922504\n",
      "This round of nMSE is: 0.999042\n",
      "This round of nMSE is: 0.789533\n",
      "This round of nMSE is: 0.973909\n",
      "Average nMSE is 0.903806.\n"
     ]
    }
   ],
   "source": [
    "pred_final = scale(pred_final)\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "for train, test in kf.split(pred_final):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = SVR(C=100000000, gamma=1e-05, epsilon=0.001, kernel='rbf')\n",
    "    # train\n",
    "    model.fit(pred_final[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(pred_final[test])\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training and predict...\n",
      "This round of nMSE is: 0.828973\n",
      "This round of nMSE is: 1.017093\n",
      "This round of nMSE is: 13.315153\n",
      "This round of nMSE is: 0.926004\n",
      "This round of nMSE is: 0.997865\n",
      "This round of nMSE is: 2.518203\n",
      "This round of nMSE is: 5.756129\n",
      "This round of nMSE is: 1.417853\n",
      "This round of nMSE is: 0.775454\n",
      "This round of nMSE is: 0.665593\n",
      "Average nMSE is 2.821832.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = ensemble.RandomForestRegressor(n_estimators=100,max_features=3,random_state=1)\n",
    "    # train\n",
    "    model.fit(pred_final[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(pred_final[test])\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training and predict...\n",
      "This round of nMSE is: 0.866383\n",
      "This round of nMSE is: 0.951472\n",
      "This round of nMSE is: 2.755952\n",
      "This round of nMSE is: 0.921553\n",
      "This round of nMSE is: 0.996998\n",
      "This round of nMSE is: 1.768380\n",
      "This round of nMSE is: 0.969684\n",
      "This round of nMSE is: 1.519276\n",
      "This round of nMSE is: 0.792986\n",
      "This round of nMSE is: 0.946074\n",
      "Average nMSE is 1.248876.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Start training and predict...\")\n",
    "kf = KFold(n_splits=10)\n",
    "nMSEs = []\n",
    "for train, test in kf.split(concat_feature):\n",
    "    # model initialize: you can tune the parameters within SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html); Or you can select other regression models\n",
    "    model = ensemble.GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=100)\n",
    "    # train\n",
    "    model.fit(pred_final[train], ground_truth[train])\n",
    "    # predict\n",
    "    predicts = model.predict(pred_final[test])\n",
    "    # nMSE(normalized Mean Squared Error) metric calculation\n",
    "    nMSE = mean_squared_error(ground_truth[test], predicts) / np.mean(np.square(ground_truth[test]))\n",
    "    nMSEs.append(nMSE)\n",
    "\n",
    "    print(\"This round of nMSE is: %f\" %(nMSE))\n",
    "\n",
    "print('Average nMSE is %f.' %(np.mean(nMSEs)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
